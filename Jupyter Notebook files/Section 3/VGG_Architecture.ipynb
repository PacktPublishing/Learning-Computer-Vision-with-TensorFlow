{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Neural Network Architecture\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../../images/keras-tensorflow-logo.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Origins\n",
    "\n",
    "VGG is a convolutional neural network model invented, back in 2014, by the **Visual Geometry Group**(VGG) at the University of Oxford. Convolutional networks have been the state of the art in visual recognition . The team's main contribution are significant improvements on the prior state of the art convolutional network, achieving, for it's time, a substantially deeper network. Since then CNNs are now much deeper (100s of layers), but they are all still based on the block architecure developed by the VGG team.\n",
    "\n",
    "# VGG Paper\n",
    "\n",
    "The corresponding published paper [*Very Deep Convolutional Networks for Large-Scale Image Recognition*](https://arxiv.org/pdf/1409.1556.pdf) is a rigorous evaluation of the network's achitecure as depth is increased.\n",
    "\n",
    "<img src=\"../../images/VGG-paper.png\" width=\"800\">\n",
    "\n",
    "# VGG Result\n",
    "\n",
    "In Summary, the VGG team secured the 1st and the 2nd places in the ImageNet Challenge for localisation and classification tasks respectively. ImageNet is a dataset of over 14 million images belonging to 1000 classes.\n",
    "\n",
    "The Results are summaries below:\n",
    "\n",
    "<img src=\"../../images/VGG-result.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Architecture\n",
    "\n",
    "The VGG team created an extremely homogeneous architecture that only performs 3x3 convolutional layers stacked on top of each other in increasing depth. Reducing volume size is handled by 2x2 max pooling. The convolutional layers are then followed by two fully-connected layers and end with softmax classifier. \n",
    "\n",
    "The achitecture comes in two size “VGG16” and “VGG19”, which stands for the number of parameterized layers in the network (best performance by configure D):\n",
    "\n",
    "<img src=\"../../images/VGGNet.png\" width=\"500\">\n",
    "\n",
    "## VGG16 Architecture\n",
    "\n",
    "<img src=\"../../images/vgg16.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Points of the VGG architecture:**\n",
    "\n",
    "- The use of only 3x3 sized filters, which is small compared to previous models that used 11x11 and 7x7 filter size. However, it turns out that the combination of two 3x3 conv layers has an effective receptive field of 5x5. This simulates a larger filter while keeping the benefits of smaller filter sizes. One of the benefits is a decrease in the number of parameters. Also, with two conv layers, we’re able to use two ReLU nonlinearity layers instead of one.\n",
    "\n",
    "- 3 conv layers back to back have an effective receptive field of 7x7.\n",
    "\n",
    "- As the spatial size of the input volumes at each layer decrease (result of the conv and pool layers), the depth of the volumes increase due to the increased number of filters as you go down the network.\n",
    "\n",
    "- The number of filters doubles after each maxpool layer. This reinforces the idea of shrinking spatial dimensions, but growing depth.\n",
    "\n",
    "- Works well on both image classification and localization tasks. Localization is treated as a regression task.\n",
    "\n",
    "- Uses ReLU  activation layers after each conv layer and trained with batch gradient descent.\n",
    "\n",
    "** Down side of VGG architecture:**\n",
    "\n",
    " - it can be slow to train on large dataset because the number of model parameters is quite large, due to its depth and its large fully-connected layers. This makes deploying VGG network difficult.\n",
    "\n",
    "- Smaller network architectures have been since proposed with comparable performance, such as SqueezeNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### VGG with TensorFlow-Keras\n",
    "-  You will implement an improved version of the VGG network in TensorFlow-Keras\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-1_1]",
   "language": "python",
   "name": "conda-env-TF-1_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
