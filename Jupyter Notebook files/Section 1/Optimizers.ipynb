{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow-Keras Optimizers\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../../images/keras-tensorflow-logo.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is one of the most popular algorithms to perform optimization and by far the most common way to optimize neural networks.\n",
    "However there exist many variants of gradient descent each with their strengths and weaknesses.\n",
    "In this lesson we will cover the most common optimization algorithms provided by TensorFlow and TF-Keras.\n",
    "You will also gain intuition towards the behaviour of different algorithms for optimizing gradient descent and how to put them to use.\n",
    "\n",
    "## Basic Gradient Descent\n",
    "Gradient descent is a way to minimize an objective function $J(\\theta)$ parameterized by a model's parameters $\\theta \\in \\mathbb{R}^d$ by updating the parameters in the opposite direction of the gradient of the objective function $\\nabla_\\theta J(\\theta)$ w.r.t. to the parameters. The learning rate $\\eta$ determines the size of the steps we take to reach a (local) minimum. In other words, we follow the direction of the slope of the surface created by the objective function downhill until we reach a valley.\n",
    "\n",
    "<img src=\"../../images/grad.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are examples of optimizers provided by TensorFlow's train module and by TF-Keras:\n",
    "\n",
    "TensorFlow train module **`tf.train`**\n",
    "\n",
    "    tf.train.GradientDescentOptimizer\n",
    "    tf.train.MomentumOptimizer\n",
    "    tf.train.RMSPropOptimizer\n",
    "    tf.train.AdadeltaOptimizer\n",
    "    tf.train.AdagradOptimizer\n",
    "    tf.train.AdamOptimizer\n",
    "    tf.train.AdagradDAOptimizer\n",
    "    \n",
    "TF-Keras optimizer module **`tf.contrib.keras.optimizers`**\n",
    "\n",
    "    tf_keras.optimizers.SGD\n",
    "    tf_keras.optimizers.Adadelta\n",
    "    tf_keras.optimizers.Adagrad\n",
    "    tf_keras.optimizers.RMSprop\n",
    "    tf_keras.optimizers.Adamax\n",
    "    tf_keras.optimizers.Nadam\n",
    "    tf_keras.optimizers.Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Variants\n",
    "\n",
    "There are three variants of gradient descent, which differ in how much data we use to compute the gradient of the objective function. Depending on the amount of data, we make a trade-off between the accuracy of the parameter update and the time it takes to perform an update.\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta; x; y)$$\n",
    "\n",
    "- **Batch gradient descent**\n",
    "    - computes the gradient of the cost function w.r.t. to the parameters Î¸ for the entire training dataset.\n",
    "- **Stochastic gradient descent**\n",
    "    - computes a parameter update for each training example x and label y\n",
    "- **Mini-batch gradient descent**\n",
    "    - computes an update for every mini-batch of nn training examples\n",
    "    \n",
    "Mini-batch gradient descent is typically the algorithm of choice when training a neural network because it combines the best of both worlds\n",
    "1. updates have lower variances than  stochastic gradient descent, therefore the objective function fluctuates less and the model converges better.\n",
    "2. the dataset doesn't need to fit in memory like for batch gradient descent, therefore the model can train on very large datasets\n",
    "3. gradient computation step is faster because the batch is smaller and make use of highly optimized matrix multiplication operation common to state-of-the-art deep learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_keras = tf.contrib.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow model inference\n",
    "model_predictions = MyDeepLearningModel(inputs)\n",
    "\n",
    "# model loss\n",
    "cross_entropy_loss = MyLossFunction(labels, model_predictions)\n",
    "\n",
    "# model evaluation metric\n",
    "evalution_metric = MyEvaluationMetric(labels, model_predictions)\n",
    "\n",
    "# model Mini-Batch gradient descent optimizer\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "# TF-Keras optimzer\n",
    "optimizer = tf_keras.optimizers.SGD(lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Short Comings of Mini-Batch Gradient Descent\n",
    "\n",
    "<img src=\"../../images/learning_rates.jpg\" width=\"400\">\n",
    "\n",
    "- **Learning rate magnitude**\n",
    "    - learning rate too large and loss function fluctuates around the minimum preventing convergence\n",
    "    - learning rate too small and training takes too long to reach convergence\n",
    "    \n",
    "- **Learning rate scheduling**\n",
    "    - annealing - reducing the learning rate according to a pre-defined schedule to allow congergence\n",
    "    - rigid method that doesn't adapt to a dataset's characteristics\n",
    "    - requires close monitoring of the training\n",
    "\n",
    "- **Same learning rate for all parameters**\n",
    "    - for parse data (some features have low frequency), we might not want to update all parameters equally\n",
    "\n",
    "- **Challenge of minimizing highly non-convex error functions**\n",
    "    - escaping suboptimal local minima or saddle points (gradients close to zero in most dimensions) can be difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Optimizer\n",
    "\n",
    "SGD tends to oscillate when the loss surface curves much more steeply in one dimension than in another, which are common around local optima.\n",
    "\n",
    "<img src=\"../../images/momentum.png\" width=\"600\">\n",
    "\n",
    "Momentum is a method that helps accelerate SGD and almost always enjoys better converge rates on deep networks. In a sense the Momentum optimizer gives potential energy to the update step. This allows the parameter vector to build up velocity in any direction that has consistent gradient. Just like pushing a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way.\n",
    "As a result, we gain faster convergence and reduced oscillation.\n",
    "\n",
    "Update step:\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta)$$\n",
    "$$\\theta = \\theta - v_t$$\n",
    "\n",
    "\n",
    "The momentum term (friction term) $\\gamma$ is usually set to 0.9 or a similar value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Momentum Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "# TF-Keras optimizer\n",
    "optimizer = tf_keras.optimizers.SGD(lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient (NAG) Optimizer\n",
    "\n",
    "Nesterov Momentum is a slightly different version of the momentum update. It enjoys stronger theoretical converge guarantees for convex functions and in practice it also consistenly works slightly better than standard momentum in neural networks.\n",
    "\n",
    "<img src=\"../../images/nesterov.jpeg\" width=\"800\">\n",
    "\n",
    "Instead of evaluating gradient at the current position (red circle), we know that our momentum is about to carry us to the tip of the green arrow. With Nesterov momentum we therefore instead evaluate the gradient at this \"looked-ahead\" position.\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta - \\gamma v_{t-1} )$$\n",
    "$$\\theta = \\theta - v_t$$\n",
    "\n",
    "This anticipatory update prevents us from going too fast (overshooting), which has significantly increased the performance of RNNs on a number of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nesterov Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n",
    "\n",
    "# TF-Keras optimizer\n",
    "optimizer = tf_keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-parameter adaptive learning rate methods\n",
    "\n",
    "So far the optimizers that we've see manipulated the learning rate globally and equally for all parameters. Tuning the learning rates is an expensive process, so there exists other methods that can adaptively tune the learning rates, and even do so per parameter to perform larger or smaller updates depending on their importance. In this section we highlight some common adaptive methods you may encounter in practice.\n",
    "\n",
    "## Adagrad Optimizer\n",
    "\n",
    "In Adagrad the learning rate is normalize by the sum of squared gradients on a per-parameter basis. This adaptive optimizer performes larger updates for infrequent and smaller updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "# Assume the gradient dx and parameter vector x\n",
    "cache += dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adagrad Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# TF-keras optimizer\n",
    "optimizer = tf_keras.optimizers.Adagrad(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaDelta and RMSprop\n",
    "\n",
    "AdaDelta and RMSprop are both very similar optimizers that improves on Adagrad by instead normalizing the learning rate with the moving average of squared gradients. This reduces the aggressive, monotonically decreasing learning rate found in Adagrad.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adadelta and RMSprop Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "\n",
    "# Adadelta\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# TF-keras optimizer\n",
    "\n",
    "# Adadelta\n",
    "optimizer = tf_keras.optimizers.Adadelta(lr=learning_rate)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = tf_keras.optimizers.RMSprop(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Moment Estimation (Adam) Optimizer\n",
    "\n",
    "Adam is often the most recommended optimizer for training Deep Neural networks. It combines idea from both RMSProp the Momentum method. It generates a \"smooth\" estimate (exponentially decaying average) of the gradients' mean and variance. Giving you the best a less noisy gradient and an adaptive learning rates for each parameter.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "m = beta1*m + (1-beta1)*dx\n",
    "v = beta2*v + (1-beta2)*(dx**2)\n",
    "x += - learning_rate * m / (np.sqrt(v) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Different Optimizers\n",
    "\n",
    "<img src=\"../../images/opt1.gif\" width=\"400\" align=\"left\">\n",
    "<img src=\"../../images/opt2.gif\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are other Tensorflow optimizers:\n",
    "\n",
    "    tf.train.AdagradDAOptimizer\n",
    "    tf_keras.optimizers.Adamax\n",
    "    tf_keras.optimizers.Nadam\n",
    "    \n",
    "I will leave it to you to explore these optimizers on your own time.\n",
    "\n",
    "## Next Lesson\n",
    "### CNN in Tensorflow and TF-Keras\n",
    "-  You will learn about CNN layers and how they work\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-1_1]",
   "language": "python",
   "name": "conda-env-TF-1_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
