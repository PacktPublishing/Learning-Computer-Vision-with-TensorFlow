{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow-Keras Layers\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../../images/keras-tensorflow-logo.jpg\" width=\"400\">\n",
    "\n",
    "\n",
    "A Deep Learning model in TensorFlow is represented as layers composed into eachother to form a trainable complex model. Each layer represents a high-level operation in the computational graph. These can be visualized as lego blocks can that be combined together and repeated across the architecture to form the neural network.\n",
    "\n",
    "Below is an example of Google's Inception model that can produce high performance image classification.\n",
    "\n",
    "<img src=\"../../images/googlenet.png\" width=\"1500\">\n",
    "\n",
    "\n",
    "Below are examples of common layers provided the TF-Keras `layers` module:\n",
    "\n",
    "** Convolutional Layers**\n",
    "```\n",
    "tf_keras.layers.Conv1D\n",
    "tf_keras.layers.Conv2D\n",
    "tf_keras.layers.Conv3D\n",
    "```\n",
    "\n",
    "** Max-Pooling Layers**\n",
    "```\n",
    "tf_keras.layers.MaxPool1D\n",
    "tf_keras.layers.MaxPool2D\n",
    "tf_keras.layers.MaxPool3D\n",
    "```\n",
    "\n",
    "** Avergae Pooling Layers**\n",
    "```\n",
    "tf_keras.layers.AvgPool1D\n",
    "tf_keras.layers.AvgPool2D\n",
    "tf_keras.layers.AvgPool3D\n",
    "```\n",
    "\n",
    "** Fully-Connected layer**\n",
    "```\n",
    "tf_keras.layers.Dense\n",
    "```\n",
    "\n",
    "** Other Layers**\n",
    "```\n",
    "tf_keras.layers.Flatten\n",
    "tf_keras.layers.Dropout\n",
    "tf_keras.layers.BatchNormalization\n",
    "```\n",
    "\n",
    "** Activation Layers**\n",
    "```\n",
    "tf_keras.activations.relu\n",
    "tf_keras.activations.sigmoid\n",
    "tf_keras.activations.softmax\n",
    "tf_keras.activations.tanh\n",
    "tf_keras.activations.elu\n",
    "tf_keras.activations.hard_sigmoid\n",
    "tf_keras.activations.softplus\n",
    "tf_keras.activations.softsign\n",
    "tf_keras.activations.linear\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_keras = tf.contrib.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "2D convolution layer - This layer creates a convolution kernel that is convolved\n",
    "with the layer input to produce a tensor of\n",
    "outputs.\n",
    "\n",
    "```\n",
    "tf_keras.layers.Conv2D\n",
    "\n",
    "Arguments:\n",
    "    filters: Integer, the dimensionality of the output space\n",
    "        (i.e. the number output of filters in the convolution).\n",
    "    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
    "        width and height of the 2D convolution window.\n",
    "        Can be a single integer to specify the same value for\n",
    "        all spatial dimensions.\n",
    "    strides: An integer or tuple/list of 2 integers,\n",
    "        specifying the strides of the convolution along the width and height.\n",
    "        Can be a single integer to specify the same value for\n",
    "        all spatial dimensions.\n",
    "        Specifying any stride value != 1 is incompatible with specifying\n",
    "        any `dilation_rate` value != 1.\n",
    "    padding: one of `\"valid\"` or `\"same\"`.\n",
    "    activation: Activation function to use.\n",
    "        If you don't specify anything, no activation is applied\n",
    "        (ie. \"linear\" activation: `a(x) = x`).\n",
    "    use_bias: Boolean, whether the layer uses a bias vector.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output filter size\n",
    "filters = 10\n",
    "\n",
    "# feature map size\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# conv2D - spatial convolution over images\n",
    "tf_keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "                       activation= tf.nn.relu, use_bias=True,\n",
    "                       kernel_initializer='glorot_uniform', bias_initializer='zeros')\n",
    "# conv1D - temporal convolution\n",
    "tf_keras.layers.Conv1D(filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "                       activation= tf.nn.relu, use_bias=True,\n",
    "                       kernel_initializer='glorot_uniform', bias_initializer='zeros')\n",
    "\n",
    "# conv3D - spatial convolution over volumes\n",
    "tf_keras.layers.Conv3D(filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "                       activation= tf.nn.relu, use_bias=True,\n",
    "                       kernel_initializer='glorot_uniform', bias_initializer='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Pooling Layer\n",
    "\n",
    "This layer create a max-pooling operation to reduces the number of parameters by downsamling the input and can also fight over-fitting.\n",
    "\n",
    "```\n",
    "tf_keras.layers.MaxPool2D\n",
    "\n",
    "Arguments:\n",
    "    pool_size: integer or tuple of 2 integers,\n",
    "        factors by which to downscale (vertical, horizontal).\n",
    "        (2, 2) will halve the input in both spatial dimension.\n",
    "        If only one integer is specified, the same window length\n",
    "        will be used for both dimensions.\n",
    "    strides: Integer, tuple of 2 integers, or None.\n",
    "        Strides values.\n",
    "        If None, it will default to `pool_size`.\n",
    "    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
    "    data_format: A string,\n",
    "        one of `channels_last` (default) or `channels_first`.\n",
    "        The ordering of the dimensions in the inputs.\n",
    "        `channels_last` corresponds to inputs with shape\n",
    "        `(batch, width, height, channels)` while `channels_first`\n",
    "        corresponds to inputs with shape\n",
    "        `(batch, channels, width, height)`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max-pooling 2D - spatial data\n",
    "tf_keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='valid', data_format=\"channels_last\")\n",
    "\n",
    "# max-pooling 1D - temporal data\n",
    "tf_keras.layers.MaxPool1D(pool_size=(2, 2), strides=(2,2), padding='valid', data_format=\"channels_last\")\n",
    "\n",
    "# max-pooling 3D - spatial or spatio-temporal\n",
    "tf_keras.layers.MaxPool3D(pool_size=(2, 2), strides=(2,2), padding='valid', data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_keras.layers.AvgPool1D\n",
    "tf_keras.layers.AvgPool2D\n",
    "tf_keras.layers.AvgPool3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Dropout consists in randomly setting\n",
    "a fraction `p` of input units to 0 at each update during training time,\n",
    "which helps prevent overfitting.\n",
    "\n",
    "```\n",
    "tf_keras.layers.Dropout\n",
    "\n",
    "Arguments:\n",
    "    rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "    noise_shape: 1D integer tensor representing the shape of the\n",
    "        binary dropout mask that will be multiplied with the input.\n",
    "        For instance, if your inputs have shape\n",
    "        `(batch_size, timesteps, features)` and\n",
    "        you want the dropout mask to be the same for all timesteps,\n",
    "        you can use `noise_shape=(batch_size, 1, features)`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "tf_keras.layers.Dropout(rate = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Batch normalization layer\n",
    "\n",
    "Normalize the activations of the previous layer at each batch,\n",
    "i.e. applies a transformation that maintains the mean activation\n",
    "close to 0 and the activation standard deviation close to 1.\n",
    "\n",
    "```\n",
    "tf_keras.layers.BatchNormalization\n",
    "\n",
    "Arguments:\n",
    "    axis: Integer, the axis that should be normalized\n",
    "        (typically the features axis).\n",
    "        For instance, after a `Conv2D` layer with\n",
    "        `data_format=\"channels_first\"`,\n",
    "        set `axis=1` in `BatchNormalization`.\n",
    "    momentum: Momentum for the moving average.\n",
    "    epsilon: Small float added to variance to avoid dividing by zero.\n",
    "    center: If True, add offset of `beta` to normalized tensor.\n",
    "        If False, `beta` is ignored.\n",
    "    scale: If True, multiply by `gamma`.\n",
    "        If False, `gamma` is not used.\n",
    "        When the next layer is linear (also e.g. `nn.relu`),\n",
    "        this can be disabled since the scaling\n",
    "        will be done by the next layer.\n",
    "    beta_initializer: Initializer for the beta weight.\n",
    "    gamma_initializer: Initializer for the gamma weight.\n",
    "    moving_mean_initializer: Initializer for the moving mean.\n",
    "    moving_variance_initializer: Initializer for the moving variance.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True,\n",
    "                                   scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "                                   moving_mean_initializer='zeros', moving_variance_initializer='ones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected (Dense) Layer\n",
    "\n",
    "Fully-connected layer computes:\n",
    "\n",
    "`output = activation(dot(input, kernel) + bias)`\n",
    "where:\n",
    "- `activation` is the element-wise activation function\n",
    "- `kernel` is a weights matrix created by the layer\n",
    "- `bias` is a bias vector created by the layer\n",
    "\n",
    "if the input to the layer has a rank greater than 2, then\n",
    "it is flattened prior to the initial dot product with `kernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully connected layer\n",
    "tf_keras.layers.Dense(units, activation=None, use_bias=True,\n",
    "                      kernel_initializer='glorot_uniform', bias_initializer='zeros')\n",
    "\n",
    "# flatten to vector\n",
    "tf_keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Activation Layer\n",
    "This is a layer of neurons that applies the non-saturating activation function. It increases the nonlinear properties of the decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_keras.activations.relu(inputs)\n",
    "tf_keras.activations.sigmoid(inputs)\n",
    "tf_keras.activations.softmax(inputs)\n",
    "tf_keras.activations.tanh(inputs)\n",
    "tf_keras.activations.elu(inputs)\n",
    "tf_keras.activations.hard_sigmoid(inputs)\n",
    "tf_keras.activations.softplus(inputs)\n",
    "tf_keras.activations.softsign(inputs)\n",
    "tf_keras.activations.linear(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### CNN layers in TF-Keras\n",
    "-  You will learn aboutthe different layers in TF-Keras\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-1_1]",
   "language": "python",
   "name": "conda-env-TF-1_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
