{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../../images/keras-tensorflow-logo.jpg\" width=\"400\">\n",
    "\n",
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "\n",
    "Convolutional Neural Networks are very similar to ordinary (fully connected) Neural Networks. They are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity function. The whole network represents a single differentiable score function. This function takes in as input raw image pixels on one end and computes class scores at the other. The output scores are fed into a loss function to compute the multinomial class probabilities.\n",
    "\n",
    "### What makes CNN special?\n",
    "CNN architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture related to the image features. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network. Below is a list of all the main components in a CNN.\n",
    "\n",
    "### Main components found in CNNs\n",
    "\n",
    "- inputs matrix - image 4D tensor\n",
    "- output class scores\n",
    "- convolutional layers\n",
    "- fully-connected layers\n",
    "- activation functions\n",
    "- max-pooling layers\n",
    "- dropout layers\n",
    "- softmax layer for multinomial class probabilities\n",
    "- loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected (Dense) Layer\n",
    "\n",
    "<div style=\"float:right;margin-right:5px;\">\n",
    "    <img src=\"../../images/SingleNeuron.png\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*Single feedforward neuron*</p>\n",
    "</div>\n",
    "<br>\n",
    "**Feedforward computation**\n",
    "\n",
    "$\\textstyle h_{W,b}(x) = f(W^Tx) = f(\\sum_{i=1}^3 W_{i}x_i +b)$ <br>\n",
    "\n",
    "$f =$ activation function <br>\n",
    "$W =$ weight vector/matrix <br>\n",
    "$b =$ bias scalar/vector <br>\n",
    "\n",
    "A fully connected (dense) layer is the most basic layer in neural networks.\n",
    "Neurons in a fully connected layer have full connections to all activations in the previous layer. The layer basically computes a weighted sum of the previous layer followed by an activation function for each neuron in the output layer. The weighted sum across all neurons can be computed with a matrix multiplication between the input vector and weight matrix followed by a bias offset.\n",
    "Fully connected layers are not spatially located since there is no weight sharing(as we'll see with convolutional layers). Therefore the input to a fully connect layer must be reshaped to a vector.\n",
    "\n",
    "\n",
    "### Fully Connected Neural Network\n",
    "<br>\n",
    "<img src=\"../../images/NN1.gif\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input. Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer.\n",
    "\n",
    "<br>\n",
    "<div style=\"float:left;margin-right:5px;\">\n",
    "    <img src=\"../../images/Conv3.jpeg\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*2D Convolution on color image*</p>\n",
    "</div>\n",
    "<div style=\"float:center;margin-right:5px;\">\n",
    "    <img src=\"../../images/neuron_model.jpeg\" width=\"350\" />\n",
    "    <p style=\"text-align:center;\">*A Neural Network \"neuron\"*</p>\n",
    "</div>\n",
    "\n",
    "Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture based in this assumption. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth.\n",
    "\n",
    "Convolutional layers provide 3 big benefits for Computer Vision:\n",
    "\n",
    "1. **Location Invariance** -  because of the sliding filters, the exact location of important features is not important, which allows the model to generalize better to unseen images (pooling also provides invariance)\n",
    "\n",
    "2. **Local connectivity** - Convolutional networks exploit spatially local correlation by enforcing a local connectivity pattern (receptive field) between neurons of adjacent layers. This is in contrast to fully connected layers that do not take into account the spatial structure of the input.\n",
    "\n",
    "3. **Compositionality** -  CNN layers are generally stacked on top of eachother. Allowing the model to construct incrementally higher-level representation of the image, making the classification task easier at the last layer.\n",
    "\n",
    "\n",
    "<img src=\"../../images/Convolution.gif\" width=\"400\">\n",
    "<center>Convolution with 3×3 Filter</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer\n",
    "\n",
    "The activation function is a layer, which applies an elementwise non-linearity to the output of a parameterized layer (ie conv, dense). The most commonly used activation for CNNs is the ReLu function.\n",
    "\n",
    "ReLU is the abbreviation of Rectified Linear Units. This is a layer of neurons that applies the non-saturating activation function $f(x)=\\max(0,x)$. It increases the nonlinear properties of the decision function and of the overall network without affecting the receptive fields of the convolution layer.\n",
    "\n",
    "Other functions are also used to increase nonlinearity, for example the saturating hyperbolic tangent $f(x)=\\tanh(x)$ and the sigmoid function $f(x)=(1+e^{-x})^{-1}$. Compared to other functions the usage of ReLU is preferable, because it results in the neural network training several times faster, without making a significant difference to generalisation accuracy.\n",
    "\n",
    "<img src=\"../../images/activations.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Pooling Layer\n",
    "A pooling layer is a type of downsampling layer. In this category, there are several layer options, with maxpooling being the most popular. This basically takes a filter (usually of size 2x2) and a stride of the same length. It then applies it to the input spacial features and outputs the maximum number in every subregion that the filter convolves around.\n",
    "\n",
    "\n",
    "Other options for pooling layers are average pooling and L2-norm pooling. The intuitive reasoning behind this layer is that once we know that a specific feature is in the original input volume (there will be a high activation value), its exact location is not as important as its relative location to the other features. This layer drastically reduces the spatial dimension (the length and the width change but not the depth) of the input tensor.\n",
    "\n",
    "This serves two main purposes:\n",
    "\n",
    "1. Reduce the amount of parameters and computation in the network\n",
    "2. Control overfitting (high train accuracy but low test accuracy)\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"float:left;margin-right:5px;\">\n",
    "    <img src=\"../../images/pool.jpeg\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*Spatial downsampling with filter size 2, stride 2*</p>\n",
    "</div>\n",
    "<div style=\"float:center;margin-right:5px;\">\n",
    "    <img src=\"../../images/maxpool.jpeg\" width=\"400\" />\n",
    "    <p style=\"text-align:center;\">*Maxpooling operation*</p>\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer downsamples the volume spatially, independently in each depth slice of the input volume. In this example, the input volume of size [224x224x64] is pooled with filter size 2, stride 2 into output volume of size [112x112x64]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Layer\n",
    "\n",
    "Neural network models can quickly become very expressive which allows them to represent very complex functions. This expressiveness is needed in image recognition due to their high dimensional and non-linear nature. However, overly complex models can lead to the problem of overfitting. Where after training, the weights of the network are so tuned to the training examples that the network doesn’t perform well and can't generalize to new unseen examples.\n",
    "\n",
    "The solution is to apply regularization. There are many ways to regularize a neural network. A common method is to add the L2-norm of the model's weights to the cost function. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. This forces the network to use all of its inputs a little rather that some of its inputs a lot.\n",
    "\n",
    "<img src=\"../../images/dropout1.png\" width=\"600\">\n",
    "\n",
    "Dropout is an extremely effective and simple regularization technique that complements the other regularization methods. This layer “drops out” a random set of activations in that layer by setting them to zero in the forward pass.  it forces the network to be redundant. That means that the network should be able to provide the right classification or output for a specific example even if some of the activations are dropped out. During testing there is no dropout applied, with the interpretation of evaluating an averaged prediction across the exponentially-sized ensemble of all sub-networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Architecture\n",
    "A CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume ( holding the class scores) through a differentiable function.\n",
    "\n",
    "The four main type of layers are:\n",
    "1. Convolutional Layer (contains trainable parameters)\n",
    "2. Fully-Connected Layer (contains trainable parameters)\n",
    "3. Pooling Layer (fixed function)\n",
    "4. Activation Layer (fixed function)\n",
    "\n",
    "<img src=\"../../images/convnet.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### CNN layers in TF-Keras\n",
    "-  You will learn aboutthe different layers in TF-Keras\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-1_1]",
   "language": "python",
   "name": "conda-env-TF-1_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
